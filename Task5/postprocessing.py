#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from optparse import OptionParser
import numpy as np
import scipy as sc
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow import keras

# NOTE: Change this to point ot the location of the saved models in your system
#models_path = "/home/student/services/tools/"
models_path = "/home/pilar/"

"""
Uses keras integration in tensorflow
"""
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical
import pickle
import os

def clean_seq(mat):
    prot_clean=[]
    for x in mat:
        if "/" not in x:
            prot_clean.append(x)
    return prot_clean


#BLOSUM function

def BLOSUMAUG(mat):
    strings = []
    probs = []
    stringsin = []
    with open("/home/pilar/blosum62.txt") as matrix_file:
        matrix = matrix_file.read()
    lines = matrix.strip().split('\n')
    header = lines.pop(0)
    columns = header.split()
    matrix = {}
    for row in lines:
        entries = row.split()
        row_name = entries.pop(0)
        matrix[row_name] = {}
        if len(entries) != len(columns):
            raise Exception('Improper entry number in row')
        for column_name in columns:
            matrix[row_name][column_name] = int(entries.pop(0))
    for count in range(0,mat.shape[0]):
        stringin = mat[count]
        if len(stringin)==12:
            strings.append(stringin)
            probs.append(1)
            stringsin.append(stringin)
            for num in range(0,len(stringin)):
                string = list(stringin)
                char=string[num]
                #Retrieve the aa with highest similarity
                listaas = dict(map(reversed, matrix.get(char).items()))
                listprob = np.array(list(listaas.keys()))
                listprob[::-1].sort()
                nn = int(listprob[1])
                chrf = listaas.get(nn)
                prob = (np.exp(nn))/(sum(np.exp(listprob[1:])))
                string[num] = chrf
                string = "".join(string)
                strings.append(string)
                probs.append(prob)
                stringsin.append(stringin)
    augmented = pd.DataFrame({'original sequence':stringsin,'peptide after BLOSUM':strings,'probability BLOSUM':probs}).drop_duplicates(subset='peptide after BLOSUM').reset_index(drop=True)
    return augmented


    #Majority voting. If 6 or more of the peptides generated by blosum have predicted the opposite we change the prediction for our nn
    
    cc=0
    current_score= 0
    count_1=0
    peptides= pd.DataFrame(columns=['original sequence', 'extracted antigen','extended sequence', 'original Prediction', 'changed Prediction','Probability','FPKM', 'Gene symbol', 'Haplo' ])
    current_original=''

    for index, row in df_haplo.iterrows():

        if row['original sequence']!=current_original:
            cc=cc+1
            current_score=row['Prediction']
            current_original= row['original sequence']
            counter=0
            peptides.loc[cc]= [row['original sequence'],row['original sequence'], data.loc[data['seq']==row['original sequence'], 'seq_extended'].iloc[0], row['Prediction'], row['Prediction'], row['Probability epitope'], data.loc[data['seq']==row['original sequence'], 'FPKM'].iloc[0], data.loc[data['seq']==row['original sequence'], 'gene_symbol'].iloc[0], Haplo]
        else:
            if row['Prediction']!=current_score:
                counter=counter+1
               # peptides.loc[
                if counter>6:
                    peptides.loc[cc, 'changed Prediction']= row['Prediction']
    peptides.to_csv(OUTpath, index=False)

if __name__ == '__main__':
    main()
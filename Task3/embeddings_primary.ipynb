{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV_AP9yiyEtD"
   },
   "source": [
    "# BERT feature extraction for each given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zwvx3CxDyLMn"
   },
   "source": [
    "## Librares and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9494,
     "status": "ok",
     "timestamp": 1653501125324,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "GD3l6ZpQ97Dq",
    "outputId": "da444f8c-f566-42c2-c177-eea0a7a045e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tape_proteins in c:\\users\\migue\\anaconda3\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: tensorboardX in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (2.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (3.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (4.62.3)\n",
      "Requirement already satisfied: lmdb in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (2.26.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (1.7.1)\n",
      "Requirement already satisfied: biopython in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tape_proteins) (1.79)\n",
      "Requirement already satisfied: numpy in c:\\users\\migue\\anaconda3\\lib\\site-packages (from biopython->tape_proteins) (1.20.3)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.5 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from boto3->tape_proteins) (1.26.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from boto3->tape_proteins) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from boto3->tape_proteins) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from botocore<1.27.0,>=1.26.5->boto3->tape_proteins) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from botocore<1.27.0,>=1.26.5->boto3->tape_proteins) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.5->boto3->tape_proteins) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from requests->tape_proteins) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from requests->tape_proteins) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from requests->tape_proteins) (2.0.4)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tensorboardX->tape_proteins) (3.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\migue\\anaconda3\\lib\\site-packages (from tqdm->tape_proteins) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tape_proteins\n",
    "#!pip install awscli --ignore-installed six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16190,
     "status": "ok",
     "timestamp": 1653501145340,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "H_t5fISe_Moy",
    "outputId": "b554c4e6-e010-46ec-851d-cbe9005d9200"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "from tape import UniRepModel\n",
    "import numpy as np\n",
    "model = ProteinBertModel.from_pretrained('bert-base')\n",
    "tokenizer = TAPETokenizer(vocab='iupac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rWyLAaW61aX2"
   },
   "outputs": [],
   "source": [
    "def clip_long_seq(seq, max_len):\n",
    "  if(len(seq) > max_len):\n",
    "    seq = seq[0:max_len]\n",
    "  return seq\n",
    "def pad_sequence(seq,max_len):\n",
    "  while(len(seq) < max_len):\n",
    "    seq = seq + \"<pad>\"\n",
    "  return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2473,
     "status": "ok",
     "timestamp": 1653476593485,
     "user": {
      "displayName": "Fran Lara",
      "userId": "11629251796772385327"
     },
     "user_tz": -120
    },
    "id": "sFrOYa7bDkip",
    "outputId": "b51fe444-0680-44d5-96cd-f1c3a477e013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYVnpRKyyS5W"
   },
   "source": [
    "## Feature vector for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1653506058605,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "3AXFHMNbJBq6",
    "outputId": "cedb81af-50ac-4d3e-d50f-e8b945eaea8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = []\n",
    "with  open('Database.txt') as fp:\n",
    "    contents = fp.read()\n",
    "    for entry in contents.split('-'):\n",
    "      entry = entry.replace('\\n','')\n",
    "      entries.append(entry)\n",
    "entries.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lleAcaCUWwxZ"
   },
   "outputs": [],
   "source": [
    "n = 30\n",
    "strings_30 = []\n",
    "for entry in entries:\n",
    "  split_strings = [entry[index : index + n] for index in range(0, len(entry), n)]\n",
    "  '''for string in split_strings:\n",
    "    if(len(string)<n):\n",
    "      split_strings = split_strings[:-1]\n",
    "      string = pad_sequence(string,n)\n",
    "      split_strings.append(string)'''\n",
    "\n",
    "  strings_30.append(split_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9QGenBwvgUk7"
   },
   "outputs": [],
   "source": [
    "list_len = []\n",
    "for string in strings_30:\n",
    "  list_len.append(len(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1653506064827,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "PFDC8Z9UXedr",
    "outputId": "2a1b70f5-bc6d-44e4-8d35-a32cf925b42d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971603"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 25268,
     "status": "error",
     "timestamp": 1653503758439,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "V3oqjiEkduoi",
    "outputId": "247b0b2f-d389-4840-a049-eaa294a4e2c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migue\\AppData\\Local\\Temp/ipykernel_16696/428392496.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  token_ids = torch.tensor([tokenizer.encode(s)])\n"
     ]
    }
   ],
   "source": [
    "#test_entries = entries[1:10]\n",
    "ctr = 0\n",
    "file_write = open(\"output_primary.txt\",\"w\")\n",
    "for string in strings_30:\n",
    "  for s in string:\n",
    "    s = clip_long_seq(s, 1024)\n",
    "    token_ids = torch.tensor([tokenizer.encode(s)])\n",
    "    output = model(token_ids)\n",
    "    sq = torch.squeeze(output[0],dim=0)\n",
    "    avg_output = torch.mean(sq,0)\n",
    "    avg_output_corr = torch.clip(avg_output, min=-1,max=1)\n",
    "    #print(torch.mean(avg_output_corr))\n",
    "    file_write.write(str(ctr)+\"\\n\")\n",
    "    file_write.write(str(avg_output_corr) + \"\\n\")\n",
    "    ctr+=1\n",
    "    #pooled_output = output[1]\n",
    "    #file_write.write(str(avg_output_corr) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5IuSc0xEfQu"
   },
   "outputs": [],
   "source": [
    "#test_entries = entries[1:10]\n",
    "ctr = 0\n",
    "file_write = open(\"/content/drive/MyDrive/output_primary.txt\",\"w\")\n",
    "for entry in entries:\n",
    "  entry = clip_long_seq(entry, 1024)\n",
    "  token_ids = torch.tensor([tokenizer.encode(entry)])\n",
    "  output = model(token_ids)\n",
    "  sq = torch.squeeze(output[0],dim=0)\n",
    "  avg_output = torch.mean(sq,0)\n",
    "  avg_output_corr = torch.clip(avg_output, min=-1,max=1)\n",
    "  #print(torch.mean(avg_output_corr))\n",
    "  ctr+=1\n",
    "  file_write.write(str(avg_output_corr) + \"\\n\")\n",
    "  #pooled_output = output[1]\n",
    "  #file_write.write(str(avg_output_corr) + \"\\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEV48dytyjA9"
   },
   "source": [
    "## Feature vector for secondary structure predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtFZSSU6JP-C"
   },
   "outputs": [],
   "source": [
    "prediction_file = '/content/drive/MyDrive/prediction.txt'\n",
    "file1 = open(prediction_file, 'r')\n",
    "Lines = file1.readlines()\n",
    "#final_lines = [\" \".join(line) for line in Lines]\n",
    "#spaced_amino_s = [char+' ' for line in Lines for char in line]\n",
    "#amino_string_s = \"\".join(spaced_amino_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTpaljfkU_KD"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "ctr = 0\n",
    "test_lines = Lines[0:10]\n",
    "file_write = open(\"output_secondary.txt\",\"w\")\n",
    "for line in Lines:\n",
    "  line_str = line.rstrip(\"\\n\")\n",
    "  line_str = clip_long_seq(line_str, 1024)\n",
    "  token_ids = torch.tensor([tokenizer.encode(line_str)])\n",
    "  output = model(token_ids)\n",
    "  sq = torch.squeeze(output[0],dim=0)\n",
    "  avg_output = torch.mean(sq,0)\n",
    "  avg_output_corr = torch.clip(avg_output, min=-1,max=1)\n",
    "  #print(torch.mean(avg_output_corr))\n",
    "  ctr += 1\n",
    "  file_write.write(str(avg_output_corr) + \"\\n\")\n",
    "  #pooled_output = output[1]\n",
    "  #file_write.write(str(avg_output_corr) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1653412734675,
     "user": {
      "displayName": "MIGUEL ANGEL VILLALBA OLIVA",
      "userId": "07438907336029814614"
     },
     "user_tz": -120
    },
    "id": "Gr-J8WZ5E5l9",
    "outputId": "62653999-5730-4fb2-cf9c-d8c1ec73248d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85450\n",
      "2049\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(final_lines))\n",
    "print(len(final_lines[1]))\n",
    "print(len(final_lines[1].rstrip(\"\\n\")))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
